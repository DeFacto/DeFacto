{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'algorithms'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e4b61bff0cd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnatural_language_claims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'algorithms'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from algorithms.natural_language_claims.temp import constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Fake News Classifiers\n",
    "\n",
    "I wrote a longer explanation of the methodology and approach for detecting fake news using scikit-learn on DataCamp (and you can [find the notebook on my GitHub](https://github.com/kjam/random_hackery/blob/master/Attempting%20to%20detect%20fake%20news.ipynb)). I would start there if you are curious as to why I chose the data, what I learned about the models and so forth.\n",
    "\n",
    "In this notebook, I wanted to compare some of the features learned by each classifier to see if there was overlap or patterns in the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'constants' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a0f80883f18c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET_FAKE_OR_REAL_NEWS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'constants' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "df = pd.read_csv(constants.DATASET_FAKE_OR_REAL_NEWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models\n",
    "\n",
    "Now I have my vectors and I can create my different classifiers. In my post I noted that there is definitely noise in the dataset, so we should expect to see that reflected in our features. Normally, I would spend some time cleaning the data, but this was a small proof of concept and investigation. I hoped merely that at least one model would be able to correct for the noise.\n",
    "\n",
    "I will compare the following models (and training data):\n",
    "\n",
    "- multinomialNB with counts (`sgd_count_clf`)\n",
    "- multinomialNB with tf-idf (`mn_tfidf_clf`)\n",
    "- passive aggressive with tf-idf (`pa_tfidf_clf`)\n",
    "- linear svc with tf-idf (`svc_tfidf_clf`)\n",
    "- linear sgd with tf-idf (`sgd_tfidf_clf`)\n",
    "\n",
    "For speed and clarity, I am primarily not doing parameter tuning, although this could be added as a step (perhaps in a scikit-learn Pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mn_count_clf = MultinomialNB(alpha=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.893\n"
     ]
    }
   ],
   "source": [
    "mn_count_clf.fit(count_train, y_train)\n",
    "pred = mn_count_clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mn_tfidf_clf = MultinomialNB(alpha=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.898\n"
     ]
    }
   ],
   "source": [
    "mn_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = mn_tfidf_clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pa_tfidf_clf = PassiveAggressiveClassifier(n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.936\n"
     ]
    }
   ],
   "source": [
    "pa_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = pa_tfidf_clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_tfidf_clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.936\n"
     ]
    }
   ],
   "source": [
    "svc_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = svc_tfidf_clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_tfidf_clf = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.935\n"
     ]
    }
   ],
   "source": [
    "sgd_tfidf_clf.fit(tfidf_train, y_train)\n",
    "pred = sgd_tfidf_clf.predict(tfidf_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_tfidf_clf.decision_function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mn_count_clf.predict_proba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc704487c50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc7045aa470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0).clf()\n",
    "\n",
    "for model, name in [ (mn_count_clf, 'multinomial nb count'),\n",
    "                     (mn_tfidf_clf, 'multinomial nb tfidf'),\n",
    "                     (pa_tfidf_clf, 'passive aggressive'),\n",
    "                     (svc_tfidf_clf, 'svc'),\n",
    "                     (sgd_tfidf_clf, 'sgd')]:\n",
    "    if 'count' in name:\n",
    "        pred = model.predict_proba(count_test)[:,1]\n",
    "    elif 'multinomial' in name:\n",
    "        pred = model.predict_proba(tfidf_test)[:,1]\n",
    "    else: \n",
    "        pred = model.decision_function(tfidf_test)\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test.values, pred, pos_label='REAL')\n",
    "    plt.plot(fpr,tpr,label=\"{}\".format(name))\n",
    "\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introspecting models\n",
    "\n",
    "My main goal for this notebook is not to compare accuracy, but to compare features learned. To do so, we can use the method shown in this [very useful StackOverflow answer](https://stackoverflow.com/a/26980472) to show significant features in a binary classifier. I will use a modified version to return top features for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FAKE': [(-5.0037843689346166, '2016'),\n",
       "  (-4.277305568486705, 'hillary'),\n",
       "  (-4.0350915183149096, 'october'),\n",
       "  (-3.1806448908807727, 'share'),\n",
       "  (-2.8815773205015938, 'november'),\n",
       "  (-2.8666938637773289, 'article'),\n",
       "  (-2.4798414650537599, 'print'),\n",
       "  (-2.4201304678498081, 'oct'),\n",
       "  (-2.3433926084640739, 'advertisement'),\n",
       "  (-2.3395571770879613, 'email')],\n",
       " 'REAL': [(2.1808685120507083, 'sen'),\n",
       "  (2.234671182489476, 'conservative'),\n",
       "  (2.2416121002195353, 'rush'),\n",
       "  (2.2972192911919938, 'gop'),\n",
       "  (2.3732434195226073, 'candidates'),\n",
       "  (2.4629979709446763, 'islamic'),\n",
       "  (2.4773530113737925, 'cruz'),\n",
       "  (2.6462184011798473, 'says'),\n",
       "  (2.7516393660233773, 'tuesday'),\n",
       "  (4.7173961017325494, 'said')]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_informative_feature_for_binary_classification(vectorizer, classifier, n=100):\n",
    "    \"\"\"\n",
    "    See: https://stackoverflow.com/a/26980472\n",
    "    \n",
    "    Identify most important features if given a vectorizer and binary classifier. Set n to the number\n",
    "    of weighted features you would like to show. (Note: current implementation merely prints and does not \n",
    "    return top classes.)\n",
    "    \n",
    "    Modified by @kjam to support a dict return.\n",
    "    \"\"\"\n",
    "\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "\n",
    "    return {class_labels[0]: topn_class1,\n",
    "            class_labels[1]: topn_class2\n",
    "    }\n",
    "\n",
    "\n",
    "most_informative_feature_for_binary_classification(tfidf_vectorizer, pa_tfidf_clf, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [(mn_count_clf, count_vectorizer),\n",
    "               (mn_tfidf_clf, tfidf_vectorizer),\n",
    "               (pa_tfidf_clf, tfidf_vectorizer),\n",
    "               (svc_tfidf_clf, tfidf_vectorizer),\n",
    "               (sgd_tfidf_clf, tfidf_vectorizer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for clf, vct in classifiers:\n",
    "    results[clf] = most_informative_feature_for_binary_classification(vct, clf, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True): {'FAKE': [(-16.067750538483136,\n",
       "    '0000'),\n",
       "   (-16.067750538483136, '000035'),\n",
       "   (-16.067750538483136, '0001'),\n",
       "   (-16.067750538483136, '0001pt'),\n",
       "   (-16.067750538483136, '000km'),\n",
       "   (-16.067750538483136, '0011'),\n",
       "   (-16.067750538483136, '006s'),\n",
       "   (-16.067750538483136, '007'),\n",
       "   (-16.067750538483136, '007s'),\n",
       "   (-16.067750538483136, '008s')],\n",
       "  'REAL': [(-5.6759590828633062, 'republican'),\n",
       "   (-5.5822987943478246, 'campaign'),\n",
       "   (-5.5205424220494219, 'new'),\n",
       "   (-5.463370874939617, 'state'),\n",
       "   (-5.4591625312696053, 'obama'),\n",
       "   (-5.4299498700212414, 'president'),\n",
       "   (-5.403667459399097, 'people'),\n",
       "   (-4.9293585357529537, 'clinton'),\n",
       "   (-4.5413068577119997, 'trump'),\n",
       "   (-4.424753408851144, 'said')]},\n",
       " MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True): {'FAKE': [(-12.641778440826338,\n",
       "    '0000'),\n",
       "   (-12.641778440826338, '000035'),\n",
       "   (-12.641778440826338, '0001'),\n",
       "   (-12.641778440826338, '0001pt'),\n",
       "   (-12.641778440826338, '000km'),\n",
       "   (-12.641778440826338, '0011'),\n",
       "   (-12.641778440826338, '006s'),\n",
       "   (-12.641778440826338, '007'),\n",
       "   (-12.641778440826338, '007s'),\n",
       "   (-12.641778440826338, '008s')],\n",
       "  'REAL': [(-6.4523190824225267, 'cruz'),\n",
       "   (-6.4520765155758752, 'state'),\n",
       "   (-6.3976966482380719, 'republican'),\n",
       "   (-6.3763430603633546, 'campaign'),\n",
       "   (-6.3243977353920071, 'president'),\n",
       "   (-6.2546017970213645, 'sanders'),\n",
       "   (-6.1446218997380431, 'obama'),\n",
       "   (-5.7568172481528066, 'clinton'),\n",
       "   (-5.5960857857331119, 'said'),\n",
       "   (-5.3575239145044948, 'trump')]},\n",
       " PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
       "               loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
       "               shuffle=True, verbose=0, warm_start=False): {'FAKE': [(-5.0037843689346166,\n",
       "    '2016'),\n",
       "   (-4.277305568486705, 'hillary'),\n",
       "   (-4.0350915183149096, 'october'),\n",
       "   (-3.1806448908807727, 'share'),\n",
       "   (-2.8815773205015938, 'november'),\n",
       "   (-2.8666938637773289, 'article'),\n",
       "   (-2.4798414650537599, 'print'),\n",
       "   (-2.4201304678498081, 'oct'),\n",
       "   (-2.3433926084640739, 'advertisement'),\n",
       "   (-2.3395571770879613, 'email')],\n",
       "  'REAL': [(2.1808685120507083, 'sen'),\n",
       "   (2.234671182489476, 'conservative'),\n",
       "   (2.2416121002195353, 'rush'),\n",
       "   (2.2972192911919938, 'gop'),\n",
       "   (2.3732434195226073, 'candidates'),\n",
       "   (2.4629979709446763, 'islamic'),\n",
       "   (2.4773530113737925, 'cruz'),\n",
       "   (2.6462184011798473, 'says'),\n",
       "   (2.7516393660233773, 'tuesday'),\n",
       "   (4.7173961017325494, 'said')]},\n",
       " LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0): {'FAKE': [(-2.5736814908121546, '2016'),\n",
       "   (-2.5339784525989919, 'hillary'),\n",
       "   (-2.2832614162685676, 'october'),\n",
       "   (-1.7249562036691735, 'article'),\n",
       "   (-1.7001446508928462, 'november'),\n",
       "   (-1.6804834300736398, 'share'),\n",
       "   (-1.4612983733594904, 'election'),\n",
       "   (-1.3994873012662765, 'print'),\n",
       "   (-1.3618751024531663, 'war'),\n",
       "   (-1.3083277387871728, 'advertisement')],\n",
       "  'REAL': [(1.3417963104839152, 'friday'),\n",
       "   (1.3487556116279853, 'monday'),\n",
       "   (1.3541835774262374, 'cruz'),\n",
       "   (1.3789186129515472, 'gop'),\n",
       "   (1.391986648809342, 'candidates'),\n",
       "   (1.42223589051593, 'conservative'),\n",
       "   (1.4570595544275122, 'islamic'),\n",
       "   (1.583430926557112, 'says'),\n",
       "   (1.6805120631475248, 'tuesday'),\n",
       "   (3.4802133345492661, 'said')]},\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "        verbose=0, warm_start=False): {'FAKE': [(-4.0368542796731672,\n",
       "    'hillary'),\n",
       "   (-3.9415962776092299, '2016'),\n",
       "   (-3.5908554894598583, 'october'),\n",
       "   (-2.9541171959620938, 'article'),\n",
       "   (-2.4630358409768536, 'november'),\n",
       "   (-2.3438330926676341, 'share'),\n",
       "   (-2.2554734531640017, 'election'),\n",
       "   (-2.242891218216291, 'print'),\n",
       "   (-2.2321091609087156, 'war'),\n",
       "   (-2.0727343954339923, 'advertisement')],\n",
       "  'REAL': [(2.0189319382877136, 'sen'),\n",
       "   (2.1431342291026096, 'monday'),\n",
       "   (2.149722617934235, 'candidates'),\n",
       "   (2.1632433067908252, 'islamic'),\n",
       "   (2.19377373469827, 'cruz'),\n",
       "   (2.2062998720665608, 'conservative'),\n",
       "   (2.212874664940506, 'friday'),\n",
       "   (2.3429869218058208, 'says'),\n",
       "   (2.5005362826740662, 'tuesday'),\n",
       "   (5.0443905971223906, 'said')]}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is both a bit hard to read and compare. What I really want is to see these possibly with ranks and compare the tokens to one another. Let's transform the data to look better for what we are trying to measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comparable_results = {'REAL': {}, 'FAKE': {}}\n",
    "for clf, data in results.items():\n",
    "    clf_name = clf.__class__.__name__\n",
    "    for label, features in data.items():\n",
    "        for rank, score_tuple in enumerate(features):\n",
    "            if score_tuple[1] in comparable_results[label]:\n",
    "                comparable_results[label][score_tuple[1]].append((rank + 1, clf_name))\n",
    "            else:\n",
    "                comparable_results[label][score_tuple[1]] = [(rank + 1, clf_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now these are a bit easier to compare and read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0000': [(1, 'MultinomialNB'), (1, 'MultinomialNB')],\n",
       " '000035': [(2, 'MultinomialNB'), (2, 'MultinomialNB')],\n",
       " '0001': [(3, 'MultinomialNB'), (3, 'MultinomialNB')],\n",
       " '0001pt': [(4, 'MultinomialNB'), (4, 'MultinomialNB')],\n",
       " '000km': [(5, 'MultinomialNB'), (5, 'MultinomialNB')],\n",
       " '0011': [(6, 'MultinomialNB'), (6, 'MultinomialNB')],\n",
       " '006s': [(7, 'MultinomialNB'), (7, 'MultinomialNB')],\n",
       " '007': [(8, 'MultinomialNB'), (8, 'MultinomialNB')],\n",
       " '007s': [(9, 'MultinomialNB'), (9, 'MultinomialNB')],\n",
       " '008s': [(10, 'MultinomialNB'), (10, 'MultinomialNB')],\n",
       " '2016': [(1, 'PassiveAggressiveClassifier'),\n",
       "  (1, 'LinearSVC'),\n",
       "  (2, 'SGDClassifier')],\n",
       " 'advertisement': [(9, 'PassiveAggressiveClassifier'),\n",
       "  (10, 'LinearSVC'),\n",
       "  (10, 'SGDClassifier')],\n",
       " 'article': [(6, 'PassiveAggressiveClassifier'),\n",
       "  (4, 'LinearSVC'),\n",
       "  (4, 'SGDClassifier')],\n",
       " 'election': [(7, 'LinearSVC'), (7, 'SGDClassifier')],\n",
       " 'email': [(10, 'PassiveAggressiveClassifier')],\n",
       " 'hillary': [(2, 'PassiveAggressiveClassifier'),\n",
       "  (2, 'LinearSVC'),\n",
       "  (1, 'SGDClassifier')],\n",
       " 'november': [(5, 'PassiveAggressiveClassifier'),\n",
       "  (5, 'LinearSVC'),\n",
       "  (5, 'SGDClassifier')],\n",
       " 'oct': [(8, 'PassiveAggressiveClassifier')],\n",
       " 'october': [(3, 'PassiveAggressiveClassifier'),\n",
       "  (3, 'LinearSVC'),\n",
       "  (3, 'SGDClassifier')],\n",
       " 'print': [(7, 'PassiveAggressiveClassifier'),\n",
       "  (8, 'LinearSVC'),\n",
       "  (8, 'SGDClassifier')],\n",
       " 'share': [(4, 'PassiveAggressiveClassifier'),\n",
       "  (6, 'LinearSVC'),\n",
       "  (6, 'SGDClassifier')],\n",
       " 'war': [(9, 'LinearSVC'), (9, 'SGDClassifier')]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparable_results['FAKE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I immediately noticed the multinomial models had picked up quite a bit of noise from the dataset. These models likely would have benefit from some preprocessing. I also noticed that *most* of the models had picked up what I would consider noise, such as `2016` and the words `print` and `share` (which are clearly scraping artifacts).\n",
    "\n",
    "Let's see if we can score the tokens by popularity and rank. I also wanted to add in a warning message in case I had overlap between my real and fake tokens. (This may be the case if you take a larger n-features from each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_results = {}\n",
    "for label, features in comparable_results.items():\n",
    "    for feature, ranks in features.items():\n",
    "        if feature in agg_results:\n",
    "            print(\"WARNING! DUPLICATE LABEL!!! {}\".format(feature))\n",
    "        agg_results[feature] = {\n",
    "            'label': label,\n",
    "            'agg_rank': np.mean([r[0] for r in ranks]),\n",
    "            'count': len(ranks)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can then put this into a dataframe, for easier transformations and viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame(agg_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_rank</th>\n",
       "      <th>count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000035</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001pt</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000km</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       agg_rank count label\n",
       "0000          1     2  FAKE\n",
       "000035        2     2  FAKE\n",
       "0001          3     2  FAKE\n",
       "0001pt        4     2  FAKE\n",
       "000km         5     2  FAKE"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate the top real and fake labels, I would advise to sort by count. Let's see my top 10 tokens for real and fake news ranked by the number of classifiers that used them as a top feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg_rank</th>\n",
       "      <th>count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cruz</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuesday</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>4.66667</td>\n",
       "      <td>3</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>islamic</th>\n",
       "      <td>5.66667</td>\n",
       "      <td>3</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidates</th>\n",
       "      <td>4.33333</td>\n",
       "      <td>3</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>9.5</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             agg_rank count label\n",
       "said              9.8     5  REAL\n",
       "cruz                4     4  REAL\n",
       "tuesday             9     3  REAL\n",
       "conservative  4.66667     3  REAL\n",
       "islamic       5.66667     3  REAL\n",
       "says                8     3  REAL\n",
       "candidates    4.33333     3  REAL\n",
       "president         5.5     2  REAL\n",
       "trump             9.5     2  REAL\n",
       "state               3     2  REAL"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df[comparison_df['label'] == 'REAL'].sort_values('count', ascending=0).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comparison_df' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-05a07673d62e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomparison_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomparison_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'FAKE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'comparison_df' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "comparison_df[comparison_df['label'] == 'FAKE'].sort_values('count', ascending=0).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "As expected, the bag-of-words and TF-IDF vectors didn't do much to determine meaningful features to classify fake or real news. As outlined in my DataCamp post, this problem is a lot harder than simple text classification.\n",
    "\n",
    "That said, I did learn a few things. Namely, that linear models handle noise in this case better than the Naive Bayes multinomial classifier did. Also, finding a good dataset that has been scraped from the web and tagged for this problem would likely be a great help, and worth more of my time than parameter tuning on a clearly noisy and error prone dataset.\n",
    "\n",
    "If you spend some time researching and find anything interesting, feel free to share your findings and notes in the comments or you can always reach out on Twitter (I'm [@kjam](https://twitter.com/kjam)).\n",
    "\n",
    "I hope you had some fun exploring a new NLP dataset with me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix A: Top features\n",
    "\n",
    "Once I realized the Naive Bayes classifiers had identified many noisy tokens in alphabetical order as top fake news classifiers, I decided to see just how many \"top features\" the model had. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20161 (-13.669855265684765, '00000031')\n"
     ]
    }
   ],
   "source": [
    "feature_names = count_vectorizer.get_feature_names()\n",
    "for idx, ftr_weight in enumerate(sorted(zip(mn_count_clf.coef_[0], feature_names))):\n",
    "    if ftr_weight[0] <= -16.067750538483136:\n",
    "        continue\n",
    "    print(idx, ftr_weight)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
